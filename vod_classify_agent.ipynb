{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import StringLookup\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load training data, sort by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the training data, randomly arrange it\n",
    "directory = \"./training_images/sorted/\"\n",
    "files = []\n",
    "for filename in os.listdir(directory):\n",
    "    if (filename != '.gitignore'):\n",
    "        files.append(directory+filename)\n",
    "\n",
    "# Gather the class labels\n",
    "class_labels = []\n",
    "for filepath in files:\n",
    "    filepath = filepath.split('/')[3][:-4]\n",
    "    filepath = re.sub(pattern=r\"[^a-zA-Z]\", repl=r\"\", string=filepath)\n",
    "    if (filepath not in class_labels):\n",
    "        class_labels.append(filepath)\n",
    "\n",
    "np.random.shuffle(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Segment data equally among classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 74\n",
      "Total validation samples: 3\n",
      "Total test samples: 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Split the training data into three subsets 90:5:5 (training:validation:test)\n",
    "train_samples = []\n",
    "test_samples = []\n",
    "validation_samples = []\n",
    "\n",
    "# gets 90:5:5 of each class\n",
    "for class_label in class_labels:\n",
    "    class_list = [filepath for filepath in files if class_label in filepath]\n",
    "\n",
    "    split_idx = int(0.9 * len(class_list))\n",
    "    train_samples += class_list[:split_idx]\n",
    "    test_or_val_samples = class_list[split_idx:]\n",
    "\n",
    "    val_split_idx = int(0.5 * len(test_or_val_samples))\n",
    "    validation_samples += test_or_val_samples[:val_split_idx]\n",
    "    test_samples += test_or_val_samples[val_split_idx:]\n",
    "    \n",
    "\n",
    "assert len(files) == len(train_samples) + len(validation_samples) + len(\n",
    "    test_samples\n",
    ")\n",
    "\n",
    "print(f\"Total training samples: {len(train_samples)}\")\n",
    "print(f\"Total validation samples: {len(validation_samples)}\")\n",
    "print(f\"Total test samples: {len(test_samples)}\")\n",
    "\n",
    "# a function that gets the image paths and their corresponding labels for whatever array we put in\n",
    "def get_labels(paths):\n",
    "    labels = []\n",
    "    for filepath in paths:\n",
    "        filepath = filepath.split('/')[3][:-4]\n",
    "        filepath = re.sub(pattern=r\"[^a-zA-Z]\", repl=r\"\", string=filepath)\n",
    "        labels.append(filepath)\n",
    "    return paths, labels\n",
    "\n",
    "train_img_paths, train_labels = get_labels(train_samples)\n",
    "validation_img_paths, validation_labels = get_labels(validation_samples)\n",
    "test_img_paths, test_labels = get_labels(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__ReadFile_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input filename tensor must be scalar, but had shape: [74] [Op:ReadFile]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\ValoVodReviewer\\vod_classify_agent.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/ValoVodReviewer/vod_classify_agent.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices((image_paths, labels))\u001b[39m.\u001b[39mmap(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/ValoVodReviewer/vod_classify_agent.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         process_images_labels, num_parallel_calls\u001b[39m=\u001b[39mAUTOTUNE\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/ValoVodReviewer/vod_classify_agent.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/ValoVodReviewer/vod_classify_agent.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39mbatch(batch_size)\u001b[39m.\u001b[39mcache()\u001b[39m.\u001b[39mprefetch(AUTOTUNE)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/ValoVodReviewer/vod_classify_agent.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m train_ds \u001b[39m=\u001b[39m process_images_labels(train_img_paths, train_labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/ValoVodReviewer/vod_classify_agent.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m validation_ds \u001b[39m=\u001b[39m process_images_labels(validation_img_paths, validation_labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/ValoVodReviewer/vod_classify_agent.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m test_ds \u001b[39m=\u001b[39m process_images_labels(test_img_paths, test_labels)\n",
      "\u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\ValoVodReviewer\\vod_classify_agent.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/ValoVodReviewer/vod_classify_agent.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_images_labels\u001b[39m(image_path, label):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/ValoVodReviewer/vod_classify_agent.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     image \u001b[39m=\u001b[39m preprocess_image(image_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/ValoVodReviewer/vod_classify_agent.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m: image, \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m: label}\n",
      "\u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\ValoVodReviewer\\vod_classify_agent.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/ValoVodReviewer/vod_classify_agent.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_image\u001b[39m(image_path):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/ValoVodReviewer/vod_classify_agent.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mread_file(image_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/ValoVodReviewer/vod_classify_agent.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mdecode_png(image)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/ValoVodReviewer/vod_classify_agent.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m image\n",
      "File \u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\ValoVodReviewer\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\io_ops.py:134\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(filename, name)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mio.read_file\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mio.read_file\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mread_file\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_file\u001b[39m(filename, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     99\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Reads the contents of file.\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \n\u001b[0;32m    101\u001b[0m \u001b[39m  This operation returns a tensor with the entire contents of the input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39m    A tensor of dtype \"string\", with the file contents.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_io_ops\u001b[39m.\u001b[39;49mread_file(filename, name)\n",
      "File \u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\ValoVodReviewer\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:611\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(filename, name)\u001b[0m\n\u001b[0;32m    609\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 611\u001b[0m   \u001b[39mreturn\u001b[39;00m read_file_eager_fallback(\n\u001b[0;32m    612\u001b[0m       filename, name\u001b[39m=\u001b[39;49mname, ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[0;32m    613\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[0;32m    614\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\ValoVodReviewer\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:634\u001b[0m, in \u001b[0;36mread_file_eager_fallback\u001b[1;34m(filename, name, ctx)\u001b[0m\n\u001b[0;32m    632\u001b[0m _inputs_flat \u001b[39m=\u001b[39m [filename]\n\u001b[0;32m    633\u001b[0m _attrs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m _result \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49mexecute(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mReadFile\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m, inputs\u001b[39m=\u001b[39;49m_inputs_flat,\n\u001b[0;32m    635\u001b[0m                            attrs\u001b[39m=\u001b[39;49m_attrs, ctx\u001b[39m=\u001b[39;49mctx, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n\u001b[0;32m    637\u001b[0m   _execute\u001b[39m.\u001b[39mrecord_gradient(\n\u001b[0;32m    638\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadFile\u001b[39m\u001b[39m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\ValoVodReviewer\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__ReadFile_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input filename tensor must be scalar, but had shape: [74] [Op:ReadFile]"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "padding_token = 99\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image)\n",
    "    return image\n",
    "\n",
    "def process_images_labels(image_path, label):\n",
    "    image = preprocess_image(image_path)\n",
    "    return {\"image\": image, \"label\": label}\n",
    "\n",
    "def prepare_dataset(image_paths, labels):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)).map(\n",
    "        process_images_labels, num_parallel_calls=AUTOTUNE\n",
    "    )\n",
    "    return dataset.batch(batch_size).cache().prefetch(AUTOTUNE)\n",
    "\n",
    "train_ds = process_images_labels(train_img_paths, train_labels)\n",
    "validation_ds = process_images_labels(validation_img_paths, validation_labels)\n",
    "test_ds = process_images_labels(test_img_paths, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_ds.take(1):\n",
    "    images, labels = data.element_spec[\"image\"], data.element_spec[\"label\"]\n",
    "\n",
    "    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n",
    "\n",
    "    for i in range(16):\n",
    "        img = images[i]\n",
    "        label = labels[i]\n",
    "\n",
    "        ax[i // 4, i % 4].imshow(img)\n",
    "        ax[i // 4, i % 4].set_title(label)\n",
    "        ax[i // 4, i % 4].axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
